{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Yelp WAX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Understanding your data and question\n",
    "\n",
    "You will be pulling data from the Yelp API to complete your analysis. The api, however, provides you with a lot of information that will not be pertinent to your analysis. YOu will pull data from the api and parse through it to keep only the data that you will need. In order to help you identify that information,look at the API documentation and understand what data the api will provide you. \n",
    "\n",
    "Identify which data fields you will want to keep for your analysis. \n",
    "\n",
    "https://www.yelp.com/developers/documentation/v3/get_started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Create ETL pipeline for the business data from the API\n",
    "\n",
    "Now that you know what data you need from the API, you want to write code that will execute a api call, parse those results and then insert the results into the DB.  \n",
    "\n",
    "It is helpful to break this up into three different functions (*api call, parse results, and insert into DB*) and then you can write a function/script that pull the other three functions together. \n",
    "\n",
    "Let's first do this for the Business endpoint.\n",
    "\n",
    "WAX:\n",
    "https://www.yelp.com/developers/documentation/v3/business_search\n",
    "ETL - extract, transform, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "from helper_funcs import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "biz_url =  'https://api.yelp.com/v3/businesses/search'\n",
    "rev_url = 'https://api.yelp.com/v3/businesses/{id}/reviews'\n",
    "# GET https://api.yelp.com/v3/businesses/{id}/reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what type of business do you want to search\n",
    "# term = 'gym'\n",
    "term = 'sushi'\n",
    "#where do you want to perform this search\n",
    "location = 'Brooklyn'\n",
    "# what is your other parameter you want to search against\n",
    "# categories = 'gyms'\n",
    "categories = 'restaurants'\n",
    "biz_filepath = '../data/biz_data.csv'\n",
    "rev_filepath = '../data/rev_data.csv'\n",
    "\n",
    "url_params = {\n",
    "    \"term\": term.replace(' ', '+'),\n",
    "    \"location\": location.replace(' ', '+'),\n",
    "    \"categories\" : categories,\n",
    "    \"limit\": 50,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# cwd = os.getcwd()\n",
    "# cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# biz = yelp_call(biz_url, url_params)\n",
    "# biz_parsed_ld = parse_biz_results_ld(biz['businesses'])\n",
    "# csv_append(biz_filepath, bizs_parsed_ld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted existing data.csv file.\n",
      "Created new data.csv file and added headers:\n",
      "['id', 'name', 'is_closed', 'review_count', 'zip_code', 'rating', 'price']\n",
      "Downloading data - - Done.\n",
      "Successfully gathered listings for 1000 businesses of type 'restaurants', search term 'sushi', in 'Brooklyn'.\n"
     ]
    }
   ],
   "source": [
    "max_results = 50\n",
    "fetch_biz_data(term, location, categories, biz_filepath, max_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 -  Create ETL pipeline for the restaurant review data from the API\n",
    "\n",
    "You've done this for the Businesses, now you need to do this for reviews. You will follow the same process, but your functions will be specific to reviews. Above you ahve a model of the functions you will need to write, and how to pull them together in one script. For this part, you ahve the process below "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In order to pull the reviews, you will need the business ids. So your first step will be to get all of the business ids from your businesses csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "biz_imported_data = []\n",
    "with open(biz_filepath, 'r', newline = '') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        biz_imported_data.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "biz_ids = [biz['id'] for biz in biz_imported_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SUHJfh7H2NiQx8c5OWoAyQ',\n",
       " 'e3JALGueMcc2eLXRK8HPNQ',\n",
       " 'LjAt-SP7BwIpp56TZHVsWA',\n",
       " 'LjAt-SP7BwIpp56TZHVsWA',\n",
       " 'LTfR_0NiS7OIRCfkaAJg9w',\n",
       " 'LTfR_0NiS7OIRCfkaAJg9w',\n",
       " 'KrJ6m_TkxBAPPSNH-G7rvQ',\n",
       " '0Lnp_fi3gI2bfJ8RcMDfjg',\n",
       " 'AFt1Qcec4_JNr6PWpkRYyw',\n",
       " 'EIcbGkl6bRtAi12zcjA7-A',\n",
       " '1yvEVWnJfodsReGHc8DuVQ',\n",
       " 'T2fE7hGS83Ba-QNCOqbK4A',\n",
       " 'Idx1__FUB7CqnhS4aQWGFQ',\n",
       " 'ZrzSDDj54aUlPqn4MQMKeQ',\n",
       " 'ldNAjLZ9sAM0PbPcJtz5Jg',\n",
       " 'U3ysEBmvdZXKmTdc3MxhGA',\n",
       " '_lS5EcBhVur3zQ5wxryGYw',\n",
       " 'MM5P9cKlzovYLcf5qf2SwQ',\n",
       " 'MM5P9cKlzovYLcf5qf2SwQ',\n",
       " 'B-lJd1eBLcLk1StNbgAe9w',\n",
       " 'cL8TLMCbs2B-vgy3SFtPGg',\n",
       " '27ASh8-hTL5jp5d_WQGHxw',\n",
       " '27ASh8-hTL5jp5d_WQGHxw',\n",
       " '49k7dpa5cNgKM0TBb593IA',\n",
       " 'kAM_S06FQlhtSSyrzrJb6w',\n",
       " 'tT6teP3ZfCAfvdPdDoqG4A',\n",
       " 'tT6teP3ZfCAfvdPdDoqG4A',\n",
       " '4UqmQ-zLrbICQFoDhr5XnQ',\n",
       " '4UqmQ-zLrbICQFoDhr5XnQ',\n",
       " 'lQgMrqcMZghWd45VIhkUAA',\n",
       " '0nYfyel0UwlI1qXHOjTw0w',\n",
       " '_FICyzFLQxR7N62I6qU94A',\n",
       " 'G4qZvheX74VwYvek7I8iQg',\n",
       " '91tQ4ToReVVCA5MTJi9gfw',\n",
       " 'Xk2zYFCknLOIZRv8T9z-Dw',\n",
       " 'HC18oDJ2svQoXIddP-wuyw',\n",
       " 'EXEDl7BOLZksz3Uy_RVFhw',\n",
       " 'a7rM-AOM7_xi8AlWX-Thkg',\n",
       " 'e-G1yC5u8LOcQ-fx0Lxthw',\n",
       " 'KxOAVoyJ55G-gEQqhnBpAQ',\n",
       " 'fHHpSKT9u7PQBYaMW5cEkA',\n",
       " 'pb_ZeBeT3eYtr_Ctxjzy8g',\n",
       " 'bnCZgNyG9FRXRy7g2-rcMw',\n",
       " 'etIbdlTKz2yLkvr9MWNPvw',\n",
       " 'etIbdlTKz2yLkvr9MWNPvw',\n",
       " 'qNmHq3ST2bBinAN-TatwSg',\n",
       " 'lxQ-tzFmL1tmUqZUN-CSRQ',\n",
       " 'uTVfLJO4kYuzJsfxHm-BGg',\n",
       " 'uTVfLJO4kYuzJsfxHm-BGg',\n",
       " 'uTVfLJO4kYuzJsfxHm-BGg']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biz_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write a function that takes a business id and makes a call to the API for reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "biz_imported_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_review(biz_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [{'id': 'uxJ3BdwfACraBeU_Mf3ITw',\n",
    " 'url': 'https://www.yelp.com/biz/harbor-fitness-brooklyn-5?adjust_creative=-pEsRVwee9viyT1bikndGw&hrid=uxJ3BdwfACraBeU_Mf3ITw&utm_campaign=yelp_api_v3&utm_medium=api_v3_business_reviews&utm_source=-pEsRVwee9viyT1bikndGw',\n",
    " 'text': 'My neighborhood gym, been a member for over a decade. Staff is always kind and helpful...I especially appreciate the help of Lisa Lekacos for being of great...',\n",
    " 'rating': 5,\n",
    " 'time_created': '2021-01-27 15:05:34',\n",
    " 'user': {'id': 'dj3scSObNzg_4HQ-5ZqnwQ',\n",
    "  'profile_url': 'https://www.yelp.com/user_details?userid=dj3scSObNzg_4HQ-5ZqnwQ',\n",
    "  'image_url': None,\n",
    "  'name': 'Edward C.'}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'wy0xAIOx2RpsFIGyX8rQFg',\n",
       " 'url': 'https://www.yelp.com/biz/sushi-yashin-brooklyn?adjust_creative=-pEsRVwee9viyT1bikndGw&hrid=wy0xAIOx2RpsFIGyX8rQFg&utm_campaign=yelp_api_v3&utm_medium=api_v3_business_reviews&utm_source=-pEsRVwee9viyT1bikndGw',\n",
       " 'text': 'Fresh, delicious, quality ingredients. Pickup only but fast preparation time. Would definitely order again. Great for south/central Brooklyn eaters',\n",
       " 'rating': 5,\n",
       " 'time_created': '2020-12-22 07:55:26',\n",
       " 'user': {'id': '5BaFA6CNpQA675TgQVuV7w',\n",
       "  'profile_url': 'https://www.yelp.com/user_details?userid=5BaFA6CNpQA675TgQVuV7w',\n",
       "  'image_url': 'https://s3-media1.fl.yelpcdn.com/photo/RvZUtgKIgz0NID3rtzxW8g/o.jpg',\n",
       "  'name': 'Hilary W.'}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['reviews'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write a function to parse out the relevant information from the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsed_rev_results_ld = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsed_rev_results_ld = parse_rev_results_ld(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_rev_results_ld = parse_rev_results_ld(results['reviews'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write a function to save the parse data into a csv file containing all of the reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_create(rev_filepath, parsed_rev_results_ld)\n",
    "# csv_append(rev_filepath, parsed_rev_results_ld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-778090641efd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcsv_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrev_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_review\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbiz_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrev\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbiz_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcsv_append\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrev_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_review\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbiz_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Classes/FS Data Science Immersive/Flatiron_Materials/Feb 1/wax_yelp_project/code/helper_funcs.py\u001b[0m in \u001b[0;36mcsv_create\u001b[0;34m(csv_filepath, parsed_results)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcsv_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparsed_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mdata_fields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfieldnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteheader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "csv_create(rev_filepath, get_review(biz_ids))\n",
    "for rev in biz_ids:\n",
    "    csv_append(rev_filepath, get_review(biz_ids[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Combine the functions above into a single script  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 -  Using python and pandas, write code to answer the questions below. \n",
    "\n",
    "\n",
    "- Which are the 5 most reviewed businesses in your dataset?\n",
    "- What is the highest rating recieved in your data set and how many businesses have that rating?\n",
    "- What percentage of businesses have a rating greater than or  4.5?\n",
    "- What percentage of businesses have a rating less than 3?\n",
    "- What percentage of your businesseshave a price label of one dollar sign? Two dollar signs? Three dollar signs? No dollar signs?\n",
    "- Return the text of the reviews for the most reviewed business. \n",
    "- Find the highest rated business and return text of the most recent review. If multiple business have the same rating, select the business with the most reviews. \n",
    "- Find the lowest rated business and return text of the most recent review.  If multiple business have the same rating, select the business with the least reviews. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(parsed_results, columns = ['Name', 'Zip Code', 'Rating'])\n",
    "df.set_index('Name',inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Pagination\n",
    "\n",
    "Returning to the Yelp API, the [documentation](https://www.yelp.com/developers/documentation/v3/business_search) also provides us details regarding the API limits. These often include details about the number of requests a user is allowed to make within a specified time limit and the maximum number of results to be returned. In this case, we are told that any request has a maximum of 50 results per request and defaults to 20. Furthermore, any search will be limited to a total of 1000 results. To retrieve all 1000 of these results, we would have to page through the results piece by piece, retriving 50 at a time. Processes such as these are often refered to as pagination.\n",
    "\n",
    "Now that you have an initial response, you can examine the contents of the json container. For example, you might start with ```response.json().keys()```. Here, you'll see a key for `'total'`, which tells you the full number of matching results given your query parameters. Write a loop (or ideally a function) which then makes successive API calls using the offset parameter to retrieve all of the results (or 5000 for a particularly large result set) for the original query. As you do this, be mindful of how you store the data. \n",
    "\n",
    "**Note: be mindful of the API rate limits. You can only make 5000 requests per day, and APIs can make requests too fast. Start prototyping small before running a loop that could be faulty. You can also use time.sleep(n) to add delays. For more details see https://www.yelp.com/developers/documentation/v3/rate_limiting.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
